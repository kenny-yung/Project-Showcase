{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standford/MIT lab dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from time import time\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\"\"\"General parameters applied as default parameters to the majority of the following functions\"\"\"\n",
    "# plt.rcParams[\"figure.figsize\"] = (16/2.54, 16/2.54)\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "from cycler import cycler\n",
    "colors = cycler(\n",
    "    \"color\",[\n",
    "        \"#00549F\", # 100% blue\n",
    "        \"#000000\", # black\n",
    "        \"#73BDFF\", # 40% blue\n",
    "        \"#990516\", # 100% red\n",
    "        \"#B97E00\", # 100% yellow\n",
    "        \"#C8C8C8\", # 20% gray\n",
    "        \"#FFDE95\", # 20% yellow\n",
    "        \"#FDC5CC\", # 20% red\n",
    "        \"#2C9CFF\", # 60% blue\n",
    "        \"#F95265\", # 60% red\n",
    "        \"#F6A800\", # 60% yellow\n",
    "    ],\n",
    ")\n",
    "plt.rc(\"axes\", facecolor=\"w\", axisbelow=True, grid=True, prop_cycle=colors)\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "# plt.rc(\"grid\", color=\"k\", linestyle=\"solid\", alpha =0.5)\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.top'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "path = \"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/StanfordMIT\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = pd.read_parquet(f\"{path}/combined.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = 112\n",
    "lower = 100\n",
    "combine = pd.DataFrame()\n",
    "for f in listdir(path=path):\n",
    "    if f.endswith(\".csv\"):\n",
    "        name = f[0:f.index(\".csv\")]\n",
    "        file = pd.read_csv(f\"{path}/{f}\")\n",
    "        meta = pd.read_csv(f\"{path}/metadata/{name}_Metadata.csv\")\n",
    "        file[\"soh\"] = file[\"Discharge_Capacity\"].rolling(window=2500).max()*100\n",
    "        start = file[(file[\"soh\"]>lower) & (file[\"soh\"]<upper)].index[1000]\n",
    "        file = file.iloc[start:]\n",
    "        file = file[file[\"soh\"]<upper]\n",
    "        file[\"test_id\"] = meta[\"test_id\"][0]\n",
    "        file[\"device_id\"] = meta[\"device_id\"][0]\n",
    "        combine = pd.concat([combine,file],ignore_index=True)\n",
    "combine = combine.drop(\"Aux_Voltage\",axis=1)\n",
    "combine.to_parquet(f\"{path}/combined.parquet\")\n",
    "combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the voltage distribution and choose the upper and lower threshold\n",
    "combine[\"Voltage\"].hist()\n",
    "print(combine[\"Voltage\"].quantile(0.75))\n",
    "print(combine[\"Voltage\"].quantile(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same charge curve\n",
    "file.loc[file[\"Cycle_Index\"]==20,\"Discharge_Capacity\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input feature extraction\n",
    "upper = 112\n",
    "lower = 100\n",
    "step = 1\n",
    "volt_threshold = 3.3\n",
    "train = pd.DataFrame()\n",
    "for f in listdir(path=path):\n",
    "    if f.endswith(\".csv\"):\n",
    "        df = pd.DataFrame()\n",
    "        name = f[0:f.index(\".csv\")]\n",
    "        print(name)\n",
    "        meta = pd.read_csv(f\"{path}/metadata/{name}_Metadata.csv\")\n",
    "        file = pd.read_csv(f\"{path}/{f}\")\n",
    "        file[\"soh\"] = file[\"Discharge_Capacity\"].rolling(window=2500).max()*100\n",
    "        start = file[(file[\"soh\"]>lower) & (file[\"soh\"]<upper)].index[1000]\n",
    "        file = file.iloc[start:]\n",
    "        file = file[file[\"soh\"]<upper]\n",
    "        file[\"day\"] = (file[\"DateTime\"]-file[\"DateTime\"].iloc[0])/60/60/24\n",
    "        df[\"day\"] = np.arange(int(file[\"day\"].min())+1,int(file[\"day\"].max())+1,step)\n",
    "        df[\"test_id\"] = meta[\"test_id\"][0]\n",
    "        df[\"device_id\"] = meta[\"device_id\"][0]\n",
    "        for i in df[\"day\"]:\n",
    "            data = file[(file[\"day\"]>=i-1) & (file[\"day\"]<i)]\n",
    "            df.loc[df[\"day\"]==i,\"soh\"] = data[\"soh\"].median()\n",
    "            df.loc[df[\"day\"]==i,\"dsoh\"] = data[\"soh\"].quantile(0.01)-data[\"soh\"].quantile(0.99)\n",
    "            df.loc[df[\"day\"]==i,\"temp_mean\"] = data[\"Temperature\"].mean()\n",
    "            df.loc[df[\"day\"]==i,\"temp_98q\"] = data[\"Temperature\"].quantile(0.98)\n",
    "            df.loc[df[\"day\"]==i,\"temp_2q\"] = data[\"Temperature\"].quantile(0.02)\n",
    "            df.loc[df[\"day\"]==i,\"volt_mean\"] = data[\"Voltage\"].mean()\n",
    "            df.loc[df[\"day\"]==i,\"volt_98q\"] = data[\"Voltage\"].quantile(0.98)\n",
    "            df.loc[df[\"day\"]==i,\"volt_2q\"] = data[\"Voltage\"].quantile(0.02)\n",
    "            df.loc[df[\"day\"]==i,\"volt_over\"] = data[data[\"Voltage\"]>volt_threshold][\"Voltage\"].count()\n",
    "            df.loc[df[\"day\"]==i,\"curr_mean\"] = data[\"Current\"].mean()\n",
    "            df.loc[df[\"day\"]==i,\"curr_mean_chg\"] = data[data[\"Current\"]>0][\"Current\"].mean()\n",
    "            df.loc[df[\"day\"]==i,\"curr_mean_dsc\"] = data[data[\"Current\"]<0][\"Current\"].mean()\n",
    "            df.loc[df[\"day\"]==i,\"curr_use_chg\"] = data[data[\"Current\"]>0.5][\"Current\"].mean()\n",
    "            df.loc[df[\"day\"]==i,\"curr_use_dsc\"] = data[data[\"Current\"]<-0.5][\"Current\"].mean()\n",
    "            df.loc[df[\"day\"]==i,\"curr_98q\"] = data[\"Current\"].quantile(0.98)\n",
    "            df.loc[df[\"day\"]==i,\"curr_2q\"] = data[\"Current\"].quantile(0.02)\n",
    "            pow_chg = (data[data[\"Current\"]>0][\"Voltage\"]*data[data[\"Current\"]>0][\"Current\"]).mean()\n",
    "            pow_dsg = (data[data[\"Current\"]<0][\"Voltage\"]*data[data[\"Current\"]<0][\"Current\"]).mean()\n",
    "            df.loc[df[\"day\"]==i,\"power_charge_mean\"] = pow_chg\n",
    "            df.loc[df[\"day\"]==i,\"power_discharge_mean\"] = pow_dsg\n",
    "            df.loc[df[\"day\"]==i,\"dod\"] = data[\"Cycle_Index\"].max()-data[\"Cycle_Index\"].min()\n",
    "        train = pd.concat([train,df],ignore_index=True)\n",
    "train.to_parquet(f\"{path}/training.parquet\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train[\"test_id\"]==13][\"soh\"].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import sklearn.metrics as metrics\n",
    "from accure_analytics.utils.error_metrics import mean_squared_error as rms\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f\"{path}/training.parquet\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df[\"test_id\"].unique()\n",
    "np.random.seed(200)\n",
    "verif_id = np.random.choice(ids,size=5)\n",
    "verif = df[df[\"test_id\"].isin(verif_id)]\n",
    "x_verif = verif.drop([\"test_id\",\"dsoh\",\"soh\"],axis=1)\n",
    "y_verif = verif[\"dsoh\"].values\n",
    "# train_set = df[~df[\"test_id\"].isin(verif_id)]\n",
    "train_set = df\n",
    "x = train_set.drop([\"test_id\",\"dsoh\",\"soh\"],axis=1)\n",
    "y = train_set[\"dsoh\"].values\n",
    "shuffle_set = train_set.sample(frac=1, random_state=200)\n",
    "x_shuffle = shuffle_set.drop([\"test_id\",\"dsoh\",\"soh\"],axis=1)\n",
    "y_shuffle = shuffle_set[\"dsoh\"].values\n",
    "x_scaled = sc.fit_transform(x)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_scaled, y, test_size=0.2, random_state=200)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = df.drop([\"test_id\",\"dsoh\",\"soh\",\"device_id\"],axis=1)\n",
    "y = df['dsoh']\n",
    "fig, axs = plt.subplots(6,3,figsize=(8,20),constrained_layout=True)\n",
    "fig.supylabel(\"∆Q\")\n",
    "fig.suptitle(\"Dataset Delta Scatter Plot\")\n",
    "for i in range(6):\n",
    "    for j in range(3):\n",
    "        n = 3*i+j\n",
    "        if n >= 6*3:\n",
    "            break\n",
    "        col = feat.columns[n]\n",
    "        axs[i,j].scatter(feat[col],y,c=\"#00549F\",s=1.5,label=col)\n",
    "        axs[i,j].set_xlabel(col)\n",
    "plt.savefig(\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/figures/corr_lab.svg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge \n",
    "ridge = Ridge(alpha=0)\n",
    "ridge.fit(x_train,y_train)\n",
    "pred = ridge.predict(x_test)\n",
    "print('RMSE: %.4f'%rms(y_test,pred))\n",
    "print('R2: %.4f'%metrics.r2_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso \n",
    "lasso = Lasso(alpha=0)\n",
    "lasso.fit(x_train,y_train)\n",
    "pred = lasso.predict(x_test)\n",
    "print('RMSE: %.4f'%rms(y_test,pred))\n",
    "print('R2: %.4f'%metrics.r2_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet \n",
    "en = ElasticNet(alpha=0.,l1_ratio=0.)\n",
    "en.fit(x_train,y_train)\n",
    "pred = en.predict(x_test)\n",
    "print('RMSE: %.4f'%rms(y_test,pred))\n",
    "print('R2: %.4f'%metrics.r2_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "poly_feat = PolynomialFeatures(degree=6,include_bias=False)\n",
    "poly = make_pipeline(poly_feat,LinearRegression())\n",
    "poly.fit(x_train,y_train)\n",
    "pred = poly.predict(x_test)\n",
    "print('RMSE: %.4f'%rms(y_test,pred))\n",
    "print('R2: %.4f'%metrics.r2_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process import kernels\n",
    "gpr = GaussianProcessRegressor(kernel=kernels.Matern())\n",
    "# gpr = GaussianProcessRegressor(kernel=kernels.RationalQuadratic())\n",
    "gpr.fit(x_train,y_train)\n",
    "pred = gpr.predict(x_test)\n",
    "print('RMSE: %.4f'%rms(y_test,pred))\n",
    "print('R2: %.4f'%metrics.r2_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# svr = SVR(kernel='rbf',epsilon=0.03,C=8)\n",
    "svr = SVR(kernel='linear',epsilon=0.01,C=8)\n",
    "svr.fit(x_train,y_train)\n",
    "pred = svr.predict(x_test)\n",
    "print('RMSE: %.4f'%rms(y_test,pred))\n",
    "print('R2: %.4f'%metrics.r2_score(y_test,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "pcr = make_pipeline(PCA(n_components=12), LinearRegression())\n",
    "\n",
    "pcr.fit(x_train, y_train)\n",
    "pred = pcr.predict(x_test) \n",
    "print('RMSE: %.4f'%rms(y_test,pred))\n",
    "print('R2: %.4f'%metrics.r2_score(y_test,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "pls = PLSRegression(n_components=25)\n",
    "pls.fit(x_train,y_train)\n",
    "pred = pls.predict(x_test).flatten()\n",
    "print('RMSE: %.4f'%rms(y_test,pred))\n",
    "print('R2: %.4f'%metrics.r2_score(y_test,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "nn1 = MLPRegressor(hidden_layer_sizes=(50,50,50,50),activation='relu',alpha=0.1,learning_rate='constant',random_state=100)\n",
    "nn1.fit(x_train, y_train)\n",
    "pred = nn1.predict(x_test) \n",
    "print('RMSE: %.4f'%rms(y_test,pred))\n",
    "print('R2: %.4f'%metrics.r2_score(y_test,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nn3 = MLPRegressor(hidden_layer_sizes=(200,200,100,100),activation='relu',alpha=0.07,learning_rate='constant',random_state=200)\n",
    "nn3.fit(x_train, y_train)\n",
    "pred = nn3.predict(x_test) \n",
    "print('RMSE: %.4f'%rms(y_test,pred))\n",
    "print('R2: %.4f'%metrics.r2_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [\n",
    "    (200,200,100,100)],\n",
    "    'alpha':[0.07,0.1,0.05],\n",
    "    'learning_rate':['adaptive','constant']\n",
    "    }  \n",
    "grid = GridSearchCV(MLPRegressor(), param_grid, cv=3, verbose=3) \n",
    "grid.fit(x_train, y_train)\n",
    "print(grid.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR(kernel='rbf',epsilon=0.03,C=8)\n",
    "svr.fit(x_train,y_train)\n",
    "pred = svr.predict(x_test)\n",
    "print('RMSE',rms(y_test,pred))\n",
    "print('R2',metrics.r2_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "poly_feat = PolynomialFeatures(degree=2,include_bias=False)\n",
    "poly = make_pipeline(poly_feat,LinearRegression())\n",
    "poly.fit(x_train,y_train)\n",
    "pred = poly.predict(x_test)\n",
    "print('RMSE',rms(y_test,pred))\n",
    "print('R2',metrics.r2_score(y_test,pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "pred = lr.predict(x_test)\n",
    "scores = cross_validate(lr,x_shuffle,y_shuffle,scoring='r2')\n",
    "stats = pd.DataFrame(scores).describe()\n",
    "stats.test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficient analysis from LR\n",
    "for i,v in enumerate(lr.coef_):\n",
    "    print(\"Feature: \",x.columns[i],\"=\",v)\n",
    "plt.figure(figsize=(8,5),tight_layout=True)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.bar(x.columns,np.abs(lr.coef_),color=\"#00549F\")\n",
    "plt.ylabel(\"Coefficient Magnitude\")\n",
    "plt.title(\"Input Feature Correlations from Dataset Delta\")\n",
    "plt.savefig(\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/figures/coef_lab.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect performance metrics\n",
    "from time import time\n",
    "from sklearn.model_selection import cross_validate\n",
    "result = pd.DataFrame()\n",
    "cv = 4\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(normalize=True)\n",
    "t0 = time()\n",
    "lr.fit(x_train,y_train)\n",
    "pred = lr.predict(x_test)\n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(lr,x_shuffle,y_shuffle,cv=cv,scoring='r2')).describe()\n",
    "result = result.append({'model':'Linear','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.linear_model import Ridge \n",
    "ridge = Ridge(alpha=0.5)\n",
    "t0 = time()\n",
    "ridge.fit(x_train,y_train)\n",
    "pred = ridge.predict(x_test)\n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(ridge,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'Ridge','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.linear_model import Lasso \n",
    "lasso = Lasso(alpha=0.)\n",
    "t0 = time()\n",
    "lasso.fit(x_train,y_train)\n",
    "pred = lasso.predict(x_test)\n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(lasso,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'Lasso','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.linear_model import ElasticNet \n",
    "en = ElasticNet(alpha=0.)\n",
    "t0 = time()\n",
    "en.fit(x_train,y_train)\n",
    "pred = en.predict(x_test)\n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(en,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'ElasticNet','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "poly_feat = PolynomialFeatures(degree=2,include_bias=False)\n",
    "poly = make_pipeline(poly_feat,LinearRegression())\n",
    "poly.fit(x_train,y_train)\n",
    "pred = poly.predict(x_test)\n",
    "stats = pd.DataFrame(cross_validate(poly,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'Poly','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process import kernels\n",
    "gpr = GaussianProcessRegressor(kernel=kernels.RationalQuadratic())\n",
    "t0 = time()\n",
    "gpr.fit(x_train,y_train)\n",
    "pred = gpr.predict(x_test)\n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(gpr,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'GPR','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "svr = SVR(kernel='rbf',epsilon=0.03,C=8)\n",
    "t0 = time()\n",
    "svr.fit(x_train,y_train)\n",
    "pred = svr.predict(x_test)\n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(svr,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'SVR','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "pcr = make_pipeline(PCA(n_components=19), LinearRegression())\n",
    "t0 = time()\n",
    "pcr.fit(x_train, y_train)\n",
    "pred = pcr.predict(x_test) \n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(pcr,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'PCA','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "pls = PLSRegression(n_components=20)\n",
    "t0 = time()\n",
    "pls.fit(x_train,y_train)\n",
    "pred = pls.predict(x_test).flatten()\n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(pls,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'PLS','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "# nn3 = MLPRegressor(hidden_layer_sizes=(200,200,100,100),activation='relu',alpha=0.07,learning_rate='constant')\n",
    "nn3 = MLPRegressor(hidden_layer_sizes=(50,50,50,50),activation='relu',alpha=0.1,learning_rate='constant',random_state=100)\n",
    "t0 = time()\n",
    "nn3.fit(x_train, y_train)\n",
    "pred = nn3.predict(x_test) \n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(nn3,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'MLPR','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([result,result.rank(axis=0)],axis=1).to_csv(\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/results_lab.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "models = [lr,poly,gpr,svr,nn3]\n",
    "# models = [lr,ridge,lasso,en,poly]\n",
    "# test_id = ids\n",
    "test_id = [234,163,155,167,200,230]\n",
    "num_x = 2\n",
    "num_y = 3\n",
    "fig,ax = plt.subplots(num_y,num_x,figsize=(8,5*num_y),constrained_layout=True)\n",
    "fig.suptitle(\"Dataset Delta Test Set\")\n",
    "for i in range(num_y):\n",
    "    for j in range(num_x):\n",
    "        # n = i*num_x + j\n",
    "        id = test_id[i*num_x+j]\n",
    "        data = df[df[\"test_id\"]==id]\n",
    "        actual = data['soh'].values\n",
    "        period = data.shape[0]-16\n",
    "        input = data.iloc[period:].drop([\"test_id\",\"dsoh\",\"soh\"],axis=1).values\n",
    "        input = sc.transform(input)    \n",
    "        ax[i,j].plot(actual,label='actual')\n",
    "        for model in models:\n",
    "            y = model.predict(input).flatten()\n",
    "            pred_soh = actual[0:period]\n",
    "            for q in range(0,len(y)):\n",
    "                pred_soh = np.append(pred_soh,pred_soh[-1]+y[q])\n",
    "            rmse_d = rms(data['dsoh'][period:],y)\n",
    "            rmse_s = rms(actual,pred_soh)\n",
    "            result = result.append(\n",
    "                {\"model\":model.__class__.__name__,\"RMSE_target\":rmse_d,\"RMSE_soh\":rmse_s,\"Final_diff\":(np.abs(actual[-1]-pred_soh[-1]))},ignore_index=True)\n",
    "            ax[i,j].plot(np.arange(period-1,len(pred_soh)),pred_soh[period-1:],'s-',label=str(model))\n",
    "        ax[i,j].set_ylabel(\"SOH (%)\")\n",
    "        ax[i,j].set_xlabel(\"Age (Day)\")\n",
    "        ax[i,j].set_title(f\"Test ID: {id}\")\n",
    "        ax[i,j].legend([\"Actual\",\"Linear\",\"Polynomial\",\"GPR\",\"SVR\",\"MLPR\"])\n",
    "    # plt.legend()\n",
    "display(result.groupby('model').mean())\n",
    "# result.to_csv(f\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/test_lab.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all test set\n",
    "result = pd.DataFrame()\n",
    "models = [lr,poly,gpr,svr,nn3]\n",
    "# test_id = ids\n",
    "test_id = verif_id\n",
    "n = 18\n",
    "for index,id in enumerate(test_id):\n",
    "    fig,ax = plt.subplots(figsize=(8,8))\n",
    "    data = df[df[\"test_id\"]==id]\n",
    "    actual = data['soh'].values\n",
    "    # period = data.shape[0]-n\n",
    "    period = 6\n",
    "    input = data.iloc[period:].drop([\"test_id\",\"dsoh\",\"soh\"],axis=1).values\n",
    "    input = sc.transform(input)\n",
    "    ax.plot(actual)\n",
    "    for m in models:\n",
    "        model = m\n",
    "        y  = model.predict(input).flatten()\n",
    "        pred_soh = actual[0:period]\n",
    "        for i in range(0,len(y)):\n",
    "            pred_soh = np.append(pred_soh,pred_soh[-1]+y[i])\n",
    "        rmse_d = rms(data['dsoh'][period:],y)\n",
    "        rmse_s = rms(actual,pred_soh)\n",
    "        result = result.append(\n",
    "            {\"model\":model.__class__.__name__,\"RMSE_target\":rmse_d,\"RMSE_soh\":rmse_s,\"Final_diff\":(np.abs(actual[-1]-pred_soh[-1]))},ignore_index=True)\n",
    "        ax.plot(np.arange(period-1,len(pred_soh)),pred_soh[period-1:],'^-')\n",
    "    plt.ylabel(\"SOH (%)\")\n",
    "    plt.xlabel(\"Age (Month)\")\n",
    "    # plt.title(f\"Index {index} ID:{id}\")\n",
    "    plt.title(f\"Test ID:{id}\")\n",
    "    plt.legend([\"Actual\",\"Linear\",\"Polynomial\",\"GPR\",\"SVR\",\"MLPR\"])\n",
    "result = result.groupby('model').mean()\n",
    "display(result)\n",
    "pd.concat([result,result.rank(axis=0)],axis=1).to_csv(f\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/test_lab.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytics_complete",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb4ce2ed95dd9a98ac3d29aa9c0af06fb8c0d144f0d8153cc9bd7707e3f0024d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
