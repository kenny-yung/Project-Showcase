{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import math\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from accure_io import PostgresInterface, S3Interface\n",
    "from accure_io.s3_battery_data_reader import DataNotFoundError, S3BatteryDataReader\n",
    "from accure_io._meta_data import MetaData\n",
    "from accure_io.s3 import list_bucket\n",
    "\n",
    "from accure_analytics.gaps.find_gaps import find_gaps\n",
    "from accure_analytics.cycle_counting.rainflow import calculate_rainflow\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\"\"\"General parameters applied as default parameters to the majority of the following functions\"\"\"\n",
    "# plt.rcParams[\"figure.figsize\"] = (16/2.54, 16/2.54)\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "from cycler import cycler\n",
    "colors = cycler(\n",
    "    \"color\",[\n",
    "        \"#000000\", # black\n",
    "        \"#00549F\", # 100% blue\n",
    "        \"#73BDFF\", # 40% blue\n",
    "        \"#990516\", # 100% red\n",
    "        \"#B97E00\", # 100% yellow\n",
    "        \"#C8C8C8\", # 20% gray\n",
    "        \"#FFDE95\", # 20% yellow\n",
    "        \"#FDC5CC\", # 20% red\n",
    "        \"#2C9CFF\", # 60% blue\n",
    "        \"#F95265\", # 60% red\n",
    "        \"#F6A800\", # 60% yellow\n",
    "    ],\n",
    ")\n",
    "plt.rc(\"axes\", facecolor=\"w\", axisbelow=True, grid=True, prop_cycle=colors)\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "# plt.rc(\"grid\", color=\"k\", linestyle=\"solid\", alpha =0.5)\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.top'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "# plt.style.use(\"seaborn-muted\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "level = \"pack\"\n",
    "customer = \"senec\"\n",
    "dc = S3Interface.get_latest_data_context(customer=customer)\n",
    "s3i = S3Interface(dc)\n",
    "battery_reader = S3BatteryDataReader(tenant=customer, data_version=\"latest\")\n",
    "\n",
    "health_path = \"s3://accure-production-artifacts/senec/product=reivolution/data_version=2/run_context=submit-20221204/artifact_type=result/group=FCC_monthly/\"\n",
    "\n",
    "version = \"221205\"\n",
    "ids = pd.read_parquet(f\"s3://accure-sandbox-data/kyung/{customer}/id-list/aging_accure_ids_{version}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"s3://accure-sandbox-data/kyung/{customer}/model-data/version={version}/training-set/\"\n",
    "period = 3\n",
    "window = 2\n",
    "for index,id in enumerate(ids[\"accure_id\"][25:]):\n",
    "    df = pd.DataFrame()\n",
    "    meta = battery_reader.read_meta_data(level=level, accure_id=id)\n",
    "    time_start = meta.first_timestamp\n",
    "    time_end = meta.last_timestamp\n",
    "    ts_data = s3i.get_timeseries_s3(level=level, accure_id=id, time_start=time_start, time_end=time_end)\n",
    "    ts_data = ts_data[~ts_data.index.duplicated()]\n",
    "    invalid = ts_data[\"voltage\"].isna() | ts_data[\"voltage\"]==0 | ts_data[\"current\"].isna()\n",
    "    ts_data = ts_data[~invalid]\n",
    "    nom_cap = meta.configurations.iloc[-1][\"customer_datasheet\"]['agg_capacity_design']\n",
    "    soh = pd.read_parquet(f'{health_path}FCC_accure_id={id}.parquet')['FCC_POINTS']/nom_cap*100\n",
    "    soc = ts_data['state_of_charge']\n",
    "    current = ts_data['current'] # positive = charge\n",
    "    # try:\n",
    "    #     rainflow = pd.read_parquet(f\"s3://accure-sandbox-data/kyung/{customer}/rainflow/id={id}.parquet\")\n",
    "    # except FileNotFoundError:\n",
    "    measurement_gaps = find_gaps(time_index=current.index)\n",
    "    rainflow = calculate_rainflow(soc=soc,current=current,gaps=measurement_gaps, idle_current_threshold_a=0)\n",
    "    rainflow.to_parquet(f\"s3://accure-sandbox-data/kyung/{customer}/rainflow/id={id}.parquet\")\n",
    "    dsoh = (soh.diff(periods=period).dropna()/period)\n",
    "    df[\"dsoh\"] = dsoh.to_list()\n",
    "    df[\"age\"] = dsoh.index\n",
    "    df[\"soh\"] = soh[period-1:-1].to_list()\n",
    "    for i in dsoh.index:\n",
    "        # month range of FCC point\n",
    "        date = time_start + relativedelta(months=i-1-window)\n",
    "        start = f\"{date.year}-{date.month}-01\"\n",
    "        end_date = pd.to_datetime(f\"{date.year}-{date.month}-01\")+relativedelta(months=window)\n",
    "        end = f\"{end_date.year}-{end_date.month}-01\"\n",
    "        data = ts_data[(ts_data.index>=start) & (ts_data.index<end)]\n",
    "        rf = rainflow[(rainflow[\"time_start\"]>=start)&(rainflow[\"time_end\"]<end)]\n",
    "        # df.loc[df[\"age\"]==i,\"month\"] = date.month\n",
    "        df.loc[df[\"age\"]==i,\"season\"] = np.cos((end_date.month-2)*(np.pi/6))\n",
    "        idle = (data[\"current\"]<0.5) & (data[\"current\"]>-0.5)\n",
    "        temp = data['temperature1']\n",
    "        volt = data[data[\"voltage\"]>5][\"voltage\"]\n",
    "        pow_chg = (data[data[\"current\"]>0][\"voltage\"]*data[data[\"current\"]>0][\"current\"]).mean()\n",
    "        pow_dsg = (data[data[\"current\"]<0][\"voltage\"]*data[data[\"current\"]<0][\"current\"]).mean()\n",
    "        # indicators\n",
    "        df.loc[df[\"age\"]==i,\"temp_mean\"] = temp.mean()\n",
    "        df.loc[df[\"age\"]==i,\"temp_98q\"] = temp.quantile(0.98)\n",
    "        df.loc[df[\"age\"]==i,\"temp_2q\"] = temp.quantile(0.02)\n",
    "        df.loc[df[\"age\"]==i,\"temp_spread\"] = temp.max()-temp.min()\n",
    "        df.loc[df[\"age\"]==i,\"volt_mean\"] = volt.mean()\n",
    "        df.loc[df[\"age\"]==i,\"volt_98q\"] = volt.quantile(0.98)\n",
    "        df.loc[df[\"age\"]==i,\"volt_2q\"] = volt.quantile(0.02)\n",
    "        df.loc[df[\"age\"]==i,\"curr_mean\"] = data[\"current\"].mean()\n",
    "        df.loc[df[\"age\"]==i,\"curr_mean_chg\"] = data[data[\"current\"]>0][\"current\"].mean()\n",
    "        df.loc[df[\"age\"]==i,\"curr_mean_dsc\"] = data[data[\"current\"]<0][\"current\"].mean()\n",
    "        df.loc[df[\"age\"]==i,\"curr_use_chg\"] = data[data[\"current\"]>0.5][\"current\"].mean()\n",
    "        df.loc[df[\"age\"]==i,\"curr_use_dsc\"] = data[data[\"current\"]<-0.5][\"current\"].mean()\n",
    "        df.loc[df[\"age\"]==i,\"curr_98q\"] = data[\"current\"].quantile(0.98)\n",
    "        df.loc[df[\"age\"]==i,\"curr_2q\"] = data[\"current\"].quantile(0.02)\n",
    "        # df.loc[df[\"age\"]==i,\"power\"] = (data[\"current\"]*data[\"voltage\"]).sum()\n",
    "        df.loc[df[\"age\"]==i,\"power_charge_mean\"] = pow_chg\n",
    "        df.loc[df[\"age\"]==i,\"power_discharge_mean\"] = pow_dsg\n",
    "        df.loc[df[\"age\"]==i,\"dod\"] = rf[\"dod\"].sum()\n",
    "        df.loc[df[\"age\"]==i,\"dod/h\"] = (rf[\"dod\"]/rf[\"duration_h\"]).sum()\n",
    "        df.loc[df[\"age\"]==i,\"energy_total\"] = (data[\"discharge_energy\"].max()-data[\"discharge_energy\"].min()+data[\"charge_energy\"].max()-data[\"charge_energy\"].min())\n",
    "    df[\"accure_id\"] = id\n",
    "    df.to_parquet(f\"{data_path}id={id}.parquet\")\n",
    "    print(f\"{index+1} Processed and saved id: {id}\")\n",
    "    df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"s3://accure-sandbox-data/kyung/{customer}/model-data/version={version}/training-set/\"\n",
    "files = list_bucket(path)\n",
    "df = pd.DataFrame()\n",
    "for file in files[\"filename\"]:\n",
    "    if (file.endswith(\".parquet\")):\n",
    "        df = pd.concat([df,pd.read_parquet(f\"{path}{file}\")],ignore_index=True)\n",
    "df.dropna(inplace=True)\n",
    "df.to_parquet(f\"/Users/kenny/accure_local/senec/training_{version}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"s3://accure-sandbox-data/kyung/{customer}/model-data/version={version}/test-set/\"\n",
    "files = list_bucket(path)\n",
    "df_test = pd.DataFrame()\n",
    "for file in files[\"filename\"]:\n",
    "    if (file.endswith(\".parquet\")):\n",
    "        df_test = pd.concat([df_test,pd.read_parquet(f\"{path}{file}\")],ignore_index=True)\n",
    "display(df_test.isna())\n",
    "df_test.dropna(inplace=True)\n",
    "# df.to_parquet(\"/Users/kenny/accure_local/senec/test.parquet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f\"/Users/kenny/accure_local/senec/training_{version}.parquet\")\n",
    "# df_test = pd.read_parquet(\"/Users/kenny/accure_local/senec/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check key stats of input features\n",
    "df.drop([\"accure_id\"],axis=1).describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import sklearn.metrics as metrics\n",
    "from accure_analytics.utils.error_metrics import mean_squared_error as rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data into training and test set randomly\n",
    "verif_id = ids[\"accure_id\"].sample(frac=0.1,random_state=20)\n",
    "verif = df[df[\"accure_id\"].isin(verif_id)]\n",
    "x_verif = verif.drop([\"accure_id\",\"dsoh\",\"soh\",\"month\"],axis=1)\n",
    "y_verif = verif[\"dsoh\"].values\n",
    "train_set = df[~df[\"accure_id\"].isin(verif_id)]\n",
    "x = train_set.drop([\"accure_id\",\"dsoh\",\"soh\",\"month\"],axis=1)\n",
    "y = train_set[\"dsoh\"].values\n",
    "shuffle_set = train_set.sample(frac=1, random_state=12)\n",
    "x_shuffle = shuffle_set.drop([\"accure_id\",\"dsoh\",\"soh\",\"month\"],axis=1)\n",
    "y_shuffle =  shuffle_set[\"dsoh\"].values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_scaled = sc.fit_transform(x)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_scaled, y, test_size=0.2, random_state=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by ids\n",
    "test_id = train_set[\"accure_id\"].drop_duplicates().sample(frac=0.25,random_state=200)\n",
    "test = train_set[train_set[\"accure_id\"].isin(test_id)]\n",
    "train = train_set[~train_set[\"accure_id\"].isin(test_id)]\n",
    "x_train = train.drop([\"accure_id\",\"dsoh\",\"soh\",\"month\"],axis=1)\n",
    "x_test = test.drop([\"accure_id\",\"dsoh\",\"soh\",\"month\"],axis=1)\n",
    "y_train = train[\"dsoh\"].values\n",
    "y_test = test[\"dsoh\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df.drop([\"accure_id\",\"soh\"],axis=1),diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input features to target output\n",
    "data = df.drop([\"accure_id\",\"soh\"],axis=1).sample(frac=0.3,random_state=200)\n",
    "feat = data.drop([\"dsoh\"],axis=1)\n",
    "y = data['dsoh']\n",
    "fig, axs = plt.subplots(7,3,figsize=(7,20),constrained_layout=True)\n",
    "fig.supylabel(\"∆SOH\")\n",
    "fig.suptitle(\"Dataset Alpha Scatter Plot\")\n",
    "for i in range(7):\n",
    "    for j in range(3):\n",
    "        col = feat.columns[3*i+j]   \n",
    "        axs[i,j].scatter(feat[col],y,c=\"#00549F\",s=0.5,label=col)\n",
    "        axs[i,j].set_xlabel(col)\n",
    "plt.savefig(\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/figures/corr_senec.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(x_train,y_train)\n",
    "pred = lr.predict(x_test)\n",
    "# model evaluation\n",
    "print(\"RMSE: %.6f %%\" % (np.sqrt(mean_squared_error(y_test, pred))))\n",
    "print(\"R2 score: %.4f\" % metrics.r2_score(y_test, pred))\n",
    "print(\"LR score: %.4f\" % lr.score(x_test, y_test))\n",
    "joblib.dump(lr,\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/sklearn models/senec/lr.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = np.array([])\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_set)):\n",
    "    x_train = train_set.iloc[train_index].drop([\"accure_id\",\"dsoh\",\"soh\",\"month\"],axis=1)\n",
    "    y_train = train_set.iloc[train_index][\"dsoh\"].values\n",
    "    x_test = train_set.iloc[test_index].drop([\"accure_id\",\"dsoh\",\"soh\",\"month\"],axis=1)\n",
    "    y_test = train_set.iloc[test_index][\"dsoh\"].values\n",
    "    print(f\"Fold {i}:\")\n",
    "    lr = LinearRegression(normalize=True)\n",
    "    lr.fit(x_train,y_train)\n",
    "    pred = lr.predict(x_test)\n",
    "    # model evaluation\n",
    "    rmse = (np.sqrt(mean_squared_error(y_test, pred)))\n",
    "    avg = np.append(avg,rmse)\n",
    "    print(\"RMSE: %.6f %%\" % rmse)\n",
    "    print(\"R2 score: %.4f\" % metrics.r2_score(y_test, pred))\n",
    "    print(\"LR score: %.4f\" % lr.score(x_test, y_test))\n",
    "print(avg)\n",
    "print(avg.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "lr = LinearRegression(normalize=True)\n",
    "pred = cross_val_predict(lr,x_shuffle,y_shuffle,cv=4)\n",
    "\n",
    "# model evaluation\n",
    "print(\"RMSE: %.6f\" % (np.sqrt(mean_squared_error(y, pred))))\n",
    "print(\"R2 score: %.4f\" % metrics.r2_score(y_shuffle, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,v in enumerate(lr.coef_):\n",
    "    print(\"Feature: \",x.columns[i],\"=\",v)\n",
    "    if v > 0.05:\n",
    "        print(\"High positive correlation\")\n",
    "    elif v < -0.05:\n",
    "        print(\"High negative correlation\")\n",
    "plt.figure(figsize=(8,5),tight_layout=True)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.bar(x.columns,np.abs(lr.coef_))\n",
    "plt.ylabel(\"Coefficient Magnitude\")\n",
    "plt.title(\"Input Feature Correlations from Dataset Alpha\")\n",
    "plt.savefig(\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/figures/coef_senec.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "plt.figure(figsize=(10,30))\n",
    "n_test = 8\n",
    "skip = 5\n",
    "test_id = df[\"accure_id\"].unique()[0:n_test*skip:skip]\n",
    "test = df[df[\"accure_id\"].isin(test_id)]\n",
    "for index,id in enumerate(test_id):\n",
    "    data = test[test[\"accure_id\"]==id]\n",
    "    actual = data['soh'].tolist()\n",
    "    soh_start = actual[0]\n",
    "    x = data.drop([\"accure_id\",\"dsoh\",\"soh\"],axis=1)\n",
    "    y = model.predict(x)\n",
    "    pred_soh = [soh_start]\n",
    "    for i in range(1,len(actual)):\n",
    "        pred_soh.append(pred_soh[i-1]+y[i])\n",
    "    rmse_d = rms(data['dsoh'],y)\n",
    "    rmse_s = rms(np.array(actual),pred_soh)\n",
    "    result = result.append(\n",
    "        {\"accure_id\":id,\"RMSE_target\":rmse_d,\"RMSE_soh\":rmse_s,\"Final_diff\":(np.abs(actual[-1]-pred_soh[-1]))},ignore_index=True)\n",
    "    # print('RMSE_d = %.2f %%, RMSE_s = %.2f %%' % (rmse_d,rmse_s))\n",
    "    plt.subplot(n_test,1,index+1)\n",
    "    plt.plot(np.array(pred_soh),label='prediction')\n",
    "    plt.plot(actual,label='actual')\n",
    "    plt.ylabel(\"SOH\")\n",
    "    plt.xlabel(\"Age (Month)\")\n",
    "    plt.legend()\n",
    "display(result)\n",
    "display(result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regularization - Linear least squares with l2 (Tikhonov) regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge \n",
    "ridge = Ridge(normalize=True,alpha=0)\n",
    "ridge.fit(x_train,y_train)\n",
    "pred = ridge.predict(x_test)\n",
    "# model evaluation\n",
    "print(\"RMSE: %.6f %%\" % (rms(y_test, pred)))\n",
    "print(\"R2 score: %.4f\" % metrics.r2_score(y_test, pred))\n",
    "joblib.dump(ridge,f\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/sklearn models/{customer}/ridge.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso - L1 prior as regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso \n",
    "lasso = Lasso(alpha=0)\n",
    "lasso.fit(x_train,y_train)\n",
    "pred = lasso.predict(x_test)\n",
    "# model evaluation\n",
    "print(\"RMSE: %.6f %%\" % (rms(y_test, pred)))\n",
    "print(\"R2 score: %.4f\" % metrics.r2_score(y_test, pred))\n",
    "joblib.dump(lasso,f\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/sklearn models/{customer}/lasso.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet - combined L1 and L2 priors as regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet \n",
    "en = ElasticNet(alpha=0)\n",
    "en.fit(x_train,y_train)\n",
    "pred = en.predict(x_test)\n",
    "# model evaluation\n",
    "print(\"RMSE: %.6f %%\" % (rms(y_test, pred)))\n",
    "print(\"R2 score: %.4f\" % metrics.r2_score(y_test, pred))\n",
    "joblib.dump(en,f\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/sklearn models/{customer}/en.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "poly_feat = PolynomialFeatures(degree=2,include_bias=False)\n",
    "# features = poly_feat.fit_transform(x_train)\n",
    "poly = make_pipeline(poly_feat,LinearRegression())\n",
    "# poly.fit(features,y_train)\n",
    "poly.fit(x_train,y_train)\n",
    "# pred = poly.predict(poly_feat.transform(x_test))\n",
    "pred = poly.predict(x_test)\n",
    "# model evaluation\n",
    "print(\"RMSE: %.6f %%\" % (rms(y_test, pred)))\n",
    "print(\"R2 score: %.4f\" % metrics.r2_score(y_test, pred))\n",
    "joblib.dump(poly,\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/sklearn models/senec/poly.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process import kernels\n",
    "gpr = GaussianProcessRegressor(kernel=kernels.RationalQuadratic())\n",
    "# model = GaussianProcessRegressor(kernel=0.5*kernels.RBF())\n",
    "gpr.fit(x_train,y_train)\n",
    "pred,std = gpr.predict(x_test,return_std=True)\n",
    "# model evaluation\n",
    "print(\"RMSE: %.6f %%\" % (rms(y_test, pred)))\n",
    "print(\"R2 score: %.4f\" % metrics.r2_score(y_test, pred))\n",
    "print(\"GPR score: %.4f\" % gpr.score(x_test,y_test))\n",
    "print(\"Max prediction: \", min(pred))\n",
    "joblib.dump(gpr,\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/sklearn models/senec/gpr_rq.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0=time()\n",
    "pred,std = gpr.predict(x_test,return_std=True)\n",
    "t1=time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'kernel': [\n",
    "            # kernels.RBF(),kernels.RBF(length_scale=4),\n",
    "            # kernels.RationalQuadratic(),\n",
    "            # kernels.ExpSineSquared(),\n",
    "            # kernels.Product(kernels.ConstantKernel(0.5),kernels.RBF()),\n",
    "            # 0.5*kernels.ExpSineSquared()\n",
    "            \n",
    "            ]}  \n",
    "grid = GridSearchCV(GaussianProcessRegressor(), param_grid, cv=2, verbose=3) \n",
    "grid.fit(x_train, y_train)\n",
    "print(grid.best_params_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "svr = SVR(kernel='rbf',epsilon=0.03,C=5)\n",
    "svr.fit(x_train,y_train)\n",
    "pred = svr.predict(x_test)\n",
    "# model evaluation\n",
    "print(\"RMSE: %.6f %%\" % (rms(y_test, pred)))\n",
    "print(\"R2 score: %.4f\" % metrics.r2_score(y_test, pred))\n",
    "print(\"SVR score: %.4f\" % svr.score(x_train,y_train))\n",
    "# joblib.dump(svr,\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/sklearn models/senec/svr.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR(kernel='rbf')\n",
    "svr.fit(x_train,y_train)\n",
    "pred = svr.predict(x_test)\n",
    "# model evaluation\n",
    "print(\"RMSE: %.6f %%\" % (rms(y_test, pred)))\n",
    "print(\"R2 score: %.4f\" % metrics.r2_score(y_test, pred))\n",
    "# print(\"SVR score: %.4f\" % svr.score(x_train,y_train))\n",
    "joblib.dump(svr,\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/sklearn models/senec/svr.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'kernel': ['rbf','poly','linear'],\n",
    "            'epsilon':[0.1,0.5,1]\n",
    "            }  \n",
    "grid = GridSearchCV(SVR(), param_grid, cv=2, verbose=2) \n",
    "grid.fit(x_train, y_train)\n",
    "print(grid.best_params_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principle Component Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pcr = make_pipeline(StandardScaler(), PCA(n_components=20), LinearRegression())\n",
    "pcr.fit(x_train, y_train)\n",
    "pred = pcr.predict(x_test) \n",
    "# model evaluation\n",
    "print(\"RMSE: %.6f %%\" % (rms(y_test, pred)))\n",
    "print(\"R2 score: %.4f\" % metrics.r2_score(y_test, pred))\n",
    "print(\"PCR score: %.4f\" % pcr.score(x_train,y_train))\n",
    "joblib.dump(pcr,\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/sklearn models/senec/pcr.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Least Squares Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "pls = PLSRegression(n_components=20)\n",
    "pls.fit(x_train,y_train)\n",
    "pred = pls.predict(x_test).flatten()\n",
    "# model evaluation\n",
    "print(\"RMSE: %.6f %%\" % (rms(y_test, pred)))\n",
    "print(\"R2 score: %.4f\" % metrics.r2_score(y_test, pred))\n",
    "print(\"PLSR score: %.4f\" % pls.score(x_train,y_train))\n",
    "joblib.dump(pls,\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/sklearn models/senec/pls.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, random_state=1)\n",
    "\n",
    "pcr = make_pipeline(StandardScaler(), PCA(n_components=1), LinearRegression())\n",
    "pcr.fit(X_train, Y_train)\n",
    "pca = pcr.named_steps[\"pca\"]  # retrieve the PCA step of the pipeline\n",
    "\n",
    "pls = PLSRegression(n_components=1)\n",
    "pls.fit(X_train, Y_train)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "axes[0].scatter(pca.transform(X_test), Y_test, alpha=0.3, label=\"ground truth\")\n",
    "axes[0].scatter(\n",
    "    pca.transform(X_test), pcr.predict(X_test), alpha=0.3, label=\"pred\"\n",
    ")\n",
    "axes[0].set(\n",
    "    xlabel=\"Projected data onto first PCA component\", ylabel=\"y\", title=\"PCR / PCA\"\n",
    ")\n",
    "axes[0].legend()\n",
    "axes[1].scatter(pls.transform(X_test), Y_test, alpha=0.3, label=\"ground truth\")\n",
    "axes[1].scatter(\n",
    "    pls.transform(X_test), pls.predict(X_test), alpha=0.3, label=\"pred\"\n",
    ")\n",
    "axes[1].set(xlabel=\"Projected data onto first PLS component\", ylabel=\"y\", title=\"PLS\")\n",
    "axes[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# nn = MLPRegressor(hidden_layer_sizes=100,activation='relu',alpha=0.5,learning_rate='adaptive',verbose=True)\n",
    "nn = MLPRegressor(hidden_layer_sizes=(50,50),activation='relu',alpha=0.1,learning_rate='constant')\n",
    "nn.fit(x_train, y_train)\n",
    "pred = nn.predict(x_test) \n",
    "# model evaluation\n",
    "print(\"RMSE: %.6f %%\" % (rms(y_test, pred)))\n",
    "print(\"R2 score: %.4f\" % metrics.r2_score(y_test, pred))\n",
    "print(\"Model score: %.4f\" % nn.score(x_train,y_train))\n",
    "joblib.dump(nn,\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/sklearn models/senec/nn_2l.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "nn = MLPRegressor(hidden_layer_sizes=(100,100,100,100),activation='relu',alpha=0.1,learning_rate='constant',random_state=200)\n",
    "nn.fit(x_train, y_train)\n",
    "pred = nn.predict(x_test) \n",
    "# model evaluation\n",
    "print(\"RMSE: %.6f %%\" % (rms(y_test, pred)))\n",
    "print(\"R2 score: %.4f\" % metrics.r2_score(y_test, pred))\n",
    "print(\"Model score: %.4f\" % nn.score(x_train,y_train))\n",
    "# joblib.dump(nn,\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/sklearn models/senec/nn_3l.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "nn = MLPRegressor(hidden_layer_sizes=(200,200,100,100),activation='relu',\n",
    "                alpha=0.01,learning_rate='adaptive',random_state=200,warm_start=False)\n",
    "nn.fit(x_train, y_train)\n",
    "pred = nn.predict(x_test)\n",
    "# model evaluation\n",
    "print(\"RMSE: %.6f %%\" % (rms(y_test, pred)))\n",
    "print(\"R2 score: %.4f\" % metrics.r2_score(y_test, pred))\n",
    "print(\"Model score: %.4f\" % nn.score(x_train,y_train))\n",
    "joblib.dump(nn,\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/sklearn models/senec/nn_3l.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'hidden_layer_sizes': [(100,),(250,200,200),(200,200,100),(100,50,100)],\n",
    "            'alpha':[0.07,0.1,0.15],\n",
    "            'activation':['tanh','relu']\n",
    "            }  \n",
    "grid = GridSearchCV(MLPRegressor(), param_grid, cv=2, verbose=2) \n",
    "grid.fit(x_train, y_train)\n",
    "print(grid.best_params_) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect performance metrics\n",
    "from time import time\n",
    "from sklearn.model_selection import cross_validate\n",
    "result = pd.DataFrame()\n",
    "cv = 4\n",
    "cross = pd.DataFrame()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "t0 = time()\n",
    "lr.fit(x_train,y_train)\n",
    "pred = lr.predict(x_test)\n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(lr,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'Linear','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Ridge \n",
    "ridge = Ridge(alpha=0)\n",
    "t0 = time()\n",
    "ridge.fit(x_train,y_train)\n",
    "pred = ridge.predict(x_test)\n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(ridge,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'Ridge','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.linear_model import Lasso \n",
    "lasso = Lasso(alpha=0)\n",
    "t0 = time()\n",
    "lasso.fit(x_train,y_train)\n",
    "pred = lasso.predict(x_test)\n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(lasso,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'Lasso','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.linear_model import ElasticNet \n",
    "en = ElasticNet(alpha=0)\n",
    "t0 = time()\n",
    "en.fit(x_train,y_train)\n",
    "pred = en.predict(x_test)\n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(en,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'ElasticNet','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "poly_feat = PolynomialFeatures(degree=2,include_bias=False)\n",
    "poly = make_pipeline(poly_feat,LinearRegression())\n",
    "poly.fit(x_train,y_train)\n",
    "pred = poly.predict(x_test)\n",
    "stats = pd.DataFrame(cross_validate(poly,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'Poly','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process import kernels\n",
    "gpr = GaussianProcessRegressor(kernel=kernels.RationalQuadratic())\n",
    "t0 = time()\n",
    "gpr.fit(x_train,y_train)\n",
    "pred = gpr.predict(x_test)\n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(gpr,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'GPR','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "svr = SVR(kernel='rbf',epsilon=0.03,C=5)\n",
    "t0 = time()\n",
    "svr.fit(x_train,y_train)\n",
    "pred = svr.predict(x_test)\n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(svr,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'SVR','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "pcr = make_pipeline(PCA(n_components=20), LinearRegression())\n",
    "t0 = time()\n",
    "pcr.fit(x_train, y_train)\n",
    "pred = pcr.predict(x_test) \n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(pcr,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'PCA','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "pls = PLSRegression(n_components=6)\n",
    "t0 = time()\n",
    "pls.fit(x_train,y_train)\n",
    "pred = pls.predict(x_test).flatten()\n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(pls,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'PLS','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "nn3 = MLPRegressor(hidden_layer_sizes=(200,200,100,100),activation='relu',alpha=0.01,learning_rate='adaptive',random_state=200)\n",
    "t0 = time()\n",
    "nn3.fit(x_train, y_train)\n",
    "pred = nn3.predict(x_test) \n",
    "t1 = time()\n",
    "stats = pd.DataFrame(cross_validate(nn3,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'NN','runtime':(t1-t0),'RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([result,result.rank(axis=0)],axis=1).to_csv(f\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/results_{customer}.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "path = f\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/sklearn models/{customer}\"\n",
    "lr = joblib.load(f\"{path}/lr.sav\")\n",
    "ridge = joblib.load(f\"{path}/ridge.sav\")\n",
    "lasso = joblib.load(f\"{path}/lasso.sav\")\n",
    "en = joblib.load(f\"{path}/en.sav\")\n",
    "poly = joblib.load(f\"{path}/poly.sav\")\n",
    "pls = joblib.load(f\"{path}/pls.sav\")\n",
    "pcr = joblib.load(f\"{path}/pcr.sav\")\n",
    "gpr = joblib.load(f\"{path}/gpr_rq.sav\")\n",
    "svr = joblib.load(f\"{path}/svr.sav\")\n",
    "nn1 = joblib.load(f\"{path}/nn_1l.sav\")\n",
    "nn2 = joblib.load(f\"{path}/nn_2l.sav\")\n",
    "nn3 = joblib.load(f\"{path}/nn_3l.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all test plots\n",
    "result = pd.DataFrame()\n",
    "models = [lr,poly,gpr,svr,nn3]\n",
    "test_id = verif_id\n",
    "for index,id in enumerate(test_id):\n",
    "    fig,ax = plt.subplots(figsize=(8,8))\n",
    "    data = verif[verif[\"accure_id\"]==id]\n",
    "    actual = data['soh'].values\n",
    "    # period = data.shape[0]-18\n",
    "    period = 12\n",
    "    input = data.iloc[period:].drop([\"accure_id\",\"dsoh\",\"soh\",\"month\"],axis=1).values\n",
    "    input = sc.transform(input)\n",
    "    ax.plot(actual,label='Actual')\n",
    "    for model in models:\n",
    "        y  = model.predict(input).flatten()\n",
    "        pred_soh = actual[0:period]\n",
    "        for i in range(0,len(y)):\n",
    "            pred_soh = np.append(pred_soh,pred_soh[-1]+y[i])\n",
    "        rmse_d = rms(data['dsoh'][period:],y)\n",
    "        rmse_s = rms(actual,pred_soh)\n",
    "        result = result.append(\n",
    "            {\"model\":model.__class__.__name__,\"accure_id\":id,\"RMSE_target\":rmse_d,\"RMSE_soh\":rmse_s,\"Final_diff\":(np.abs(actual[-1]-pred_soh[-1]))},ignore_index=True)\n",
    "        ax.plot(np.arange(period-1,len(pred_soh)),pred_soh[period-1:],'^-',label=str(model.__class__.__name__))\n",
    "    plt.ylabel(\"SOH (%)\")\n",
    "    plt.xlabel(\"Age (Month)\")\n",
    "    plt.title(f\"Index {index} ID:{id}\")\n",
    "    # plt.legend([\"Actual\",\"Linear\",\"Polynomial\",\"GPR\",\"SVR\",\"MLPR\"])\n",
    "    plt.legend()\n",
    "result = result.groupby('model').mean()\n",
    "display(result)\n",
    "pd.concat([result,result.rank(axis=0)],axis=1).to_csv(f\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/test_{customer}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty plots\n",
    "result = pd.DataFrame()\n",
    "models = [lr,poly,gpr,svr,nn3]\n",
    "test_id = verif_id.iloc[[19,13,10,8,4,2]]\n",
    "n = 18\n",
    "num_y = 3\n",
    "num_x = 2\n",
    "fig,ax = plt.subplots(num_y,num_x,figsize=(8,5*num_y),constrained_layout=True)\n",
    "fig.suptitle(\"Dataset Alpha Test Set\")\n",
    "# for index,id in enumerate(test_id):\n",
    "for i in range(num_y):\n",
    "    for j in range(num_x):\n",
    "        id = test_id.iloc[i*num_x+j]\n",
    "        data = verif[verif[\"accure_id\"]==id]\n",
    "        actual = data['soh'].values\n",
    "        # period = data.shape[0]-n\n",
    "        period = 12\n",
    "        input = data.iloc[period:].drop([\"accure_id\",\"dsoh\",\"soh\",\"month\"],axis=1).values\n",
    "        input = sc.transform(input)\n",
    "        ax[i,j].plot(actual)\n",
    "        for model in models:\n",
    "            y  = model.predict(input).flatten()\n",
    "            pred_soh = actual[0:period]\n",
    "            for q in range(0,len(y)):\n",
    "                pred_soh = np.append(pred_soh,pred_soh[-1]+y[q])\n",
    "            rmse_d = rms(data['dsoh'][period:],y)\n",
    "            rmse_s = rms(actual,pred_soh)\n",
    "            result = result.append(\n",
    "                {\"model\":model.__class__.__name__,\"accure_id\":id,\"RMSE_target\":rmse_d,\"RMSE_soh\":rmse_s,\n",
    "                \"Final_diff\":(np.abs(actual[-1]-pred_soh[-1]))},ignore_index=True)\n",
    "            ax[i,j].plot(np.arange(period-1,len(pred_soh)),pred_soh[period-1:],'^-')\n",
    "        ax[i,j].set_ylabel(\"SOH (%)\")\n",
    "        ax[i,j].set_xlabel(\"Age (Month)\")\n",
    "        ax[i,j].set_title(f\"Test ID:{id}\")\n",
    "        ax[i,j].legend([\"Actual\",\"Linear\",\"Polynomial\",\"GPR\",\"SVR\",\"MLPR\"])\n",
    "display(result.groupby('model').mean())\n",
    "# result.groupby('model').mean().to_csv(f\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/test_senec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "result = pd.DataFrame()\n",
    "cv = 4\n",
    "\n",
    "pred = lr.predict(x_test)\n",
    "stats = pd.DataFrame(cross_validate(lr,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'Linear','RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "pred = ridge.predict(x_test)\n",
    "stats = pd.DataFrame(cross_validate(ridge,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'Ridge','RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "pred = lasso.predict(x_test)\n",
    "stats = pd.DataFrame(cross_validate(lasso,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'Lasso','RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "pred = en.predict(x_test)\n",
    "stats = pd.DataFrame(cross_validate(en,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'ElasticNet','RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "pred = poly.predict(x_test)\n",
    "stats = pd.DataFrame(cross_validate(poly,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'Polynomial (deg=2)','RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "pred = gpr.predict(x_test)\n",
    "stats = pd.DataFrame(cross_validate(lr,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'GPR','RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "pred = svr.predict(x_test)\n",
    "stats = pd.DataFrame(cross_validate(svr,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'SVR','RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "pred = pcr.predict(x_test) \n",
    "stats = pd.DataFrame(cross_validate(pcr,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'PCA','RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "pred = pls.predict(x_test).flatten()\n",
    "stats = pd.DataFrame(cross_validate(pls,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'PLS','RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "pred = nn3.predict(x_test) \n",
    "stats = pd.DataFrame(cross_validate(nn3,x_shuffle,y_shuffle,cv=cv)).describe()\n",
    "result = result.append({'model':'Neural Network (3 Layer)','RMSE':rms(y_test,pred),\n",
    "    'R2':metrics.r2_score(y_test,pred),'CV_runtime':stats.fit_time[1]+stats.score_time[1],\n",
    "    'CV_score':stats.test_score[1],'CV_std':stats.test_score[2]},ignore_index=True)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([result,result.rank(axis=0)],axis=1).to_csv(f\"/Users/kenny/Library/CloudStorage/OneDrive-ACCUREBatteryIntelligenceGmbH/Thesis/data/results_{customer}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytics_complete",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb4ce2ed95dd9a98ac3d29aa9c0af06fb8c0d144f0d8153cc9bd7707e3f0024d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
